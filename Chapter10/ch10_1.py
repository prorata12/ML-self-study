# Supervised Learning - Regression Analysis
# 연속적 타깃 변수 예측

"""
Univariate Linear Regression 단변량 선형 회귀
<->
Multivariate Linear Regression 다변량 선형 회귀
: 몇 개의 특성을 다루느냐로 나뉨
"""

# 10.1.1 단변량 선형 회귀

# Explanatory Variable x -> Response Variable y
#       설명변수          ->        응답변수
# y  = wx + b = w0 + w1*x

# Regression Line 회귀 직선 - 포인트들을 가장 잘 표현하는 직선
# Regression Line ~ Sample Point : offset(오프셋), residual(잔차) : y값 차이


# 10.1.2 다변량 선형 회귀

# y = w0*x0 + ... + wm*xm (x0 = 1)
# y = w^T * x
